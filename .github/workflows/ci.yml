name: CI

on:
  push:
    branches: [main]
  pull_request:
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  ci:
    runs-on: ubuntu-latest
    env:
      PYTHONUNBUFFERED: "1"
      SDL_VIDEODRIVER: dummy
      MPLBACKEND: Agg
      PYGAME_HIDE_SUPPORT_PROMPT: "1"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "0.5.11"

      - name: Cache .venv
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ hashFiles('uv.lock') }}

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('pyproject.toml', 'uv.lock') }}
          restore-keys: |
            pip-${{ runner.os }}-

      - name: Cache compiled extensions
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv/archive-v0
          key: uv-archive-${{ runner.os }}-${{ hashFiles('pyproject.toml', 'uv.lock') }}

      - name: Cache test results
        uses: actions/cache@v4
        with:
          path: .pytest_cache
          key: pytest-${{ runner.os }}-${{ hashFiles('**/*.py') }}
          restore-keys: |
            pytest-${{ runner.os }}-

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Configure faster apt mirror
        run: |
          sudo sed -i 's|http://azure.archive.ubuntu.com/ubuntu/|http://mirror.enzu.com/ubuntu/|g' /etc/apt/sources.list
          sudo apt-get update

      - name: Install apt-fast
        run: |
          sudo apt-get update
          sudo apt-get install -y aria2
          wget https://raw.githubusercontent.com/ilikenwf/apt-fast/master/apt-fast
          sudo mv apt-fast /usr/local/bin/apt-fast
          sudo chmod +x /usr/local/bin/apt-fast

      - name: System packages for headless
        run: |
          sudo apt-fast install -y ffmpeg libglib2.0-0 libgl1 fonts-dejavu-core

      - name: Sync dependencies (locked)
        run: uv sync --all-extras --frozen

      - name: Migrate legacy artifacts into canonical root
        run: uv run python scripts/tools/migrate_artifacts.py

      - name: Lint
        run: |
          uv run ruff check .
          uv run ruff format --check .

      - name: Type check
        run: uvx ty check . --exit-zero

      - name: Unit tests
        run: uv run pytest -q -n auto --max-worker-restart=0

      - name: Map verification (CI mode)
        run: |
          echo "Running map verification in CI mode (scope=ci)"
          uv run python scripts/validation/verify_maps.py --scope ci --mode ci --output output/validation/map_verification.json

      - name: Upload map verification manifest
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: map-verification-manifest
          path: output/validation/map_verification.json
          if-no-files-found: warn

      - name: Restore coverage baseline
        uses: actions/cache@v4
        with:
          path: output/coverage/.coverage-baseline.json
          key: coverage-baseline-${{ github.ref_name }}
          restore-keys: |
            coverage-baseline-main

      - name: Compare coverage with baseline
        continue-on-error: true
        run: |
          if [ -f output/coverage/.coverage-baseline.json ]; then
            echo "Baseline found, comparing coverage..."
            uv run python scripts/coverage/compare_coverage.py \
              --current output/coverage/coverage.json \
              --baseline output/coverage/.coverage-baseline.json \
              --format github \
              --threshold 1.0
          else
            echo "No baseline found, skipping comparison"
          fi

      - name: Update coverage baseline (main branch only)
        if: github.ref == 'refs/heads/main' && success()
        run: |
          mkdir -p output/coverage
          cp output/coverage/coverage.json output/coverage/.coverage-baseline.json
          echo "Coverage baseline updated for main branch"

      - name: Save coverage baseline (main branch only)
        if: github.ref == 'refs/heads/main' && success()
        uses: actions/cache/save@v4
        with:
          path: output/coverage/.coverage-baseline.json
          key: coverage-baseline-${{ github.ref_name }}-${{ github.sha }}

      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: |
            output/coverage/coverage.json
            output/coverage/htmlcov/
            output/coverage/.coverage

      - name: Upload benchmark artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-artifacts
          path: output/benchmarks/
          if-no-files-found: ignore

      - name: Upload recording artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: recording-artifacts
          path: output/recordings/
          if-no-files-found: ignore

      - name: Validation smoke tests
        run: |
          echo "Running environment validation tests..."
          ./scripts/validation/test_basic_environment.sh
          ./scripts/validation/test_model_prediction.sh

          # Run full performance smoke test only on main branch or workflow_dispatch
          if [[ "${{ github.ref }}" == "refs/heads/main" || "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "Running full performance smoke test..."
            uv run python scripts/validation/performance_smoke_test.py
          else
            echo "Skipping full performance smoke test on PR branch"
          fi

      - name: Cold/warm perf regression smoke
        run: |
          BASELINE="configs/benchmarks/perf_baseline_classic_cold_warm_v1.json"
          MAX_SLOWDOWN="0.60"
          MAX_THROUGHPUT_DROP="0.50"
          MIN_SECONDS_DELTA="0.15"
          MIN_THROUGHPUT_DELTA="0.75"
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            echo "Using conservative PR perf gate profile"
            MAX_SLOWDOWN="0.75"
            MAX_THROUGHPUT_DROP="0.60"
            MIN_SECONDS_DELTA="0.20"
            MIN_THROUGHPUT_DELTA="1.00"
          fi
          CMD=(
            uv run python -m robot_sf.benchmark.perf_cold_warm
            --scenario-config configs/scenarios/archetypes/classic_crossing.yaml
            --scenario-name classic_crossing_low
            --episode-steps 48
            --cold-runs 1
            --warm-runs 2
            --baseline "$BASELINE"
            --output-json output/benchmarks/perf/cold_warm_pr_smoke.json
            --output-markdown output/benchmarks/perf/cold_warm_pr_smoke.md
            --max-slowdown-pct "$MAX_SLOWDOWN"
            --max-throughput-drop-pct "$MAX_THROUGHPUT_DROP"
            --min-seconds-delta "$MIN_SECONDS_DELTA"
            --min-throughput-delta "$MIN_THROUGHPUT_DELTA"
            --require-baseline
          )
          if [[ "${{ github.ref }}" == "refs/heads/main" || "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "Enforcing cold/warm regression gate"
            "${CMD[@]}" --fail-on-regression
          else
            echo "Running cold/warm smoke in advisory mode on PR branch"
            "${CMD[@]}"
          fi

      - name: Telemetry tracker/perf smoke
        run: |
          echo "Running telemetry tracker smoke + perf wrapper"
          uv run python scripts/validation/run_examples_smoke.py --perf-tests-only

      - name: Preflight for Tiny batch smoke
        run: |
          set -euo pipefail
          echo "Preflight: checking schema file, uv availability, and optional jq"
          SCHEMA_PATH="docs/dev/issues/social-navigation-benchmark/episode_schema.json"
          if [ ! -r "$SCHEMA_PATH" ]; then
            echo "ERROR: Schema file not found or not readable: $SCHEMA_PATH" >&2
            ls -la "$(dirname "$SCHEMA_PATH")" || true
            exit 1
          fi
          if ! command -v uv >/dev/null 2>&1; then
            echo "ERROR: 'uv' CLI not found in PATH" >&2
            exit 1
          fi
          if [ ! -x "$(command -v uv)" ]; then
            echo "ERROR: 'uv' CLI is not executable" >&2
            exit 1
          fi
          if command -v jq >/dev/null 2>&1; then
            echo "jq found; JSONL validation will be performed after smoke run"
          else
            echo "jq not found; JSONL validation will be skipped (episodes.jsonl size will still be checked)"
          fi

      - name: Tiny batch smoke
        run: |
          cat > matrix.yaml <<'YAML'
          - id: ci-smoke-uni-low-open
            density: low
            flow: uni
            obstacle: open
            groups: 0.0
            speed_var: low
            goal_topology: point
            robot_context: embedded
            repeats: 1
          YAML
          mkdir -p output/benchmarks/ci_smoke
          uv run robot_sf_bench run \
            --matrix matrix.yaml \
            --out output/benchmarks/ci_smoke/episodes.jsonl \
            --schema robot_sf/benchmark/schemas/episode.schema.v1.json \
            --horizon 3 --dt 0.1 --base-seed 0
          test -s output/benchmarks/ci_smoke/episodes.jsonl

      - name: Validate JSONL (optional jq)
        run: |
          set -euo pipefail
          if command -v jq >/dev/null 2>&1; then
            echo "Validating first JSONL record with jqâ€¦"
            head -n1 output/benchmarks/ci_smoke/episodes.jsonl | jq type >/dev/null
          else
            echo "jq not installed; skipping JSONL validation"
          fi

      - name: Upload smoke artifact on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: ci-smoke-episodes
          path: output/benchmarks/ci_smoke/episodes.jsonl

      - name: Reproducibility check (manual trigger only)
        if: github.event_name == 'workflow_dispatch'
        run: |
          echo "Running end-to-end reproducibility validation..."
          uv run python scripts/benchmark_repro_check.py

      - name: Upload reproducibility report
        if: github.event_name == 'workflow_dispatch'
        uses: actions/upload-artifact@v4
        with:
          name: reproducibility-report
          path: output/benchmarks/reproducibility_check.json

      - name: Enforce artifact root policy
        if: always()
        run: uv run python scripts/tools/check_artifact_root.py
