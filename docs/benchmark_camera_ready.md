# Camera-Ready Benchmark Campaign Workflow

This document describes the config-driven campaign workflow for generating
camera-ready benchmark outputs across multiple planners.

## Entry Point

Run the campaign CLI:

```bash
uv run python scripts/tools/run_camera_ready_benchmark.py \
  --config configs/benchmarks/camera_ready_all_planners.yaml
```

Optional:

```bash
uv run python scripts/tools/run_camera_ready_benchmark.py \
  --config configs/benchmarks/camera_ready_all_planners.yaml \
  --label draft \
  --log-level INFO
```

## Config Presets

- `configs/benchmarks/camera_ready_smoke_all_planners.yaml`
  - single scenario smoke for fast validation
- `configs/benchmarks/camera_ready_baseline_safe.yaml`
  - baseline-ready planners on full scenario suite
- `configs/benchmarks/camera_ready_all_planners.yaml`
  - baseline + experimental planners on full scenario suite

## Produced Artifacts

Campaign outputs are written under:

`output/benchmarks/camera_ready/<campaign_id>/`

Expected tree:

```text
<campaign_id>/
  campaign_manifest.json
  manifest.json
  run_meta.json
  runs/
    <planner_key>/
      episodes.jsonl
      summary.json
  reports/
    campaign_summary.json
    campaign_table.csv
    campaign_table.md
    campaign_report.md
```

Publication bundle export is written under:

`output/benchmarks/publication/`

with files generated by `export_publication_bundle`.

## Campaign Summary Semantics

`reports/campaign_summary.json` contains:

- campaign metadata/provenance (scenario hash, git hash, runtime)
- per-planner run summary from benchmark runner
- per-planner aggregate statistics (mean and CI when available)
- flattened planner comparison rows
- warning list
- publication bundle paths (if export enabled)

## Camera-Ready Table Fields

`campaign_table.csv` and `campaign_table.md` include at least:

- planner key and algorithm
- episode count and failure count
- success/collision/near-miss means
- time-to-goal normalization mean
- path efficiency mean
- comfort exposure mean
- jerk mean
- SNQI mean and CI fields (if available)

## Notes on Experimental Planners

Experimental planners are executed with explicit profile and prereq policy from
the campaign config. For dependency-sensitive planners (for example SocNav
adapters), set `socnav_missing_prereq_policy: fallback` when you want campaign
execution to continue with degraded behavior instead of hard-fail.
