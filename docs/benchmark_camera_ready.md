# Camera-Ready Benchmark Campaign Workflow

This document describes the config-driven campaign workflow for generating
camera-ready benchmark outputs across multiple planners.

## Entry Point

Run the campaign CLI:

```bash
uv run python scripts/tools/run_camera_ready_benchmark.py \
  --config configs/benchmarks/camera_ready_all_planners.yaml
```

Optional:

```bash
uv run python scripts/tools/run_camera_ready_benchmark.py \
  --config configs/benchmarks/camera_ready_all_planners.yaml \
  --label draft \
  --log-level INFO
```

For long/full campaigns, force worker log noise down:

```bash
LOGURU_LEVEL=INFO uv run python scripts/tools/run_camera_ready_benchmark.py \
  --config configs/benchmarks/camera_ready_all_planners.yaml \
  --label full_run
```

## Config Presets

- `configs/benchmarks/camera_ready_smoke_all_planners.yaml`
  - single scenario smoke for fast validation
- `configs/benchmarks/camera_ready_baseline_safe.yaml`
  - baseline-ready planners on full scenario suite
- `configs/benchmarks/camera_ready_all_planners.yaml`
  - baseline + experimental planners on full scenario suite

SNQI calibration assets used by camera-ready presets:

- `configs/benchmarks/snqi_weights_camera_ready_v1.json`
- `configs/benchmarks/snqi_baseline_camera_ready_v1.json`

## Produced Artifacts

Campaign outputs are written under:

`output/benchmarks/camera_ready/<campaign_id>/`

Expected tree:

```text
<campaign_id>/
  campaign_manifest.json
  manifest.json
  run_meta.json
  runs/
    <planner_key>/
      episodes.jsonl
      summary.json
  reports/
    campaign_summary.json
    campaign_table.csv
    campaign_table.md
    campaign_report.md
```

Publication bundle export is written under:

`output/benchmarks/publication/`

with files generated by `export_publication_bundle`.

## Campaign Summary Semantics

`reports/campaign_summary.json` contains:

- campaign metadata/provenance (scenario hash, git hash, runtime)
- per-planner run summary from benchmark runner
- per-planner aggregate statistics (mean and CI when available)
- flattened planner comparison rows
- warning list
- publication bundle paths (if export enabled)

## Reproducibility Metadata

Each campaign now stores the exact invocation and timing provenance.

Captured fields include:

- exact command used to launch the campaign (`invoked_command`)
- campaign wallclock start/end (`started_at_utc`, `finished_at_utc`)
- campaign runtime and throughput (`runtime_sec`, `episodes_per_second`)
- per-planner start/end/runtime/throughput in run entries and planner summaries

Primary locations:

- `output/benchmarks/camera_ready/<campaign_id>/reports/campaign_summary.json`
  - `campaign.invoked_command`
  - `campaign.started_at_utc`
  - `campaign.finished_at_utc`
  - `campaign.runtime_sec`
  - `campaign.episodes_per_second`
  - `runs[].started_at_utc`
  - `runs[].finished_at_utc`
  - `runs[].runtime_sec`
  - `runs[].summary.episodes_per_second`
- `output/benchmarks/camera_ready/<campaign_id>/campaign_manifest.json`
  - `invoked_command`
  - `started_at_utc`
  - `runtime_sec`
- `output/benchmarks/camera_ready/<campaign_id>/run_meta.json`
  - `invoked_command`
  - `started_at_utc`
  - `finished_at_utc`
  - `runtime_sec`
  - `episodes_per_second`
- `output/benchmarks/camera_ready/<campaign_id>/reports/campaign_report.md`
  - command in header
  - per-planner timing columns in the summary table

Quick inspection example:

```bash
jq '.campaign | {invoked_command, started_at_utc, finished_at_utc, runtime_sec, episodes_per_second}' \
  output/benchmarks/camera_ready/<campaign_id>/reports/campaign_summary.json
```

## Camera-Ready Table Fields

`campaign_table.csv` and `campaign_table.md` include at least:

- planner key and algorithm
- episode count and failure count
- success/collision/near-miss means
- time-to-goal normalization mean
- path efficiency mean
- comfort exposure mean
- jerk mean
- SNQI mean and CI fields (if available)

## Notes on Experimental Planners

Experimental planners are executed with explicit profile and prereq policy from
the campaign config. For dependency-sensitive planners (for example SocNav
adapters), set `socnav_missing_prereq_policy: fallback` when you want campaign
execution to continue with degraded behavior instead of hard-fail.

## Current Validation Snapshot

Validated on branch `codex/benchmark-camera-ready-pipeline`:

- baseline-safe calibration campaign (multi-seed `eval` set):
  - `camera_ready_baseline_safe_snqi_calib_base_20260217_122711`
  - `total_runs=3`, `successful_runs=3`, `total_episodes=405`
  - output used to derive:
    - `configs/benchmarks/snqi_baseline_camera_ready_v1.json`
- baseline-safe verification with SNQI enabled:
  - `camera_ready_baseline_safe_snqi_verify_20260217_123159`
  - `total_runs=3`, `successful_runs=3`, `total_episodes=405`
  - `snqi_mean` is numeric in campaign table (no `nan`)
- smoke all-planners with SNQI calibration enabled:
  - `camera_ready_smoke_all_planners_snqi_check_20260217_123000`
  - `total_runs=7`, `successful_runs=7`, `total_episodes=7`
  - `snqi_mean` is numeric in campaign table (no `nan`)
- full all-planners with multi-seed + SNQI enabled:
  - `camera_ready_all_planners_snqi_multiseed_verify_20260217_123437`
  - `total_runs=7`, `successful_runs=7`, `total_episodes=945`
  - `snqi_mean` is numeric for all planners in campaign table
- smoke all-planners:
  - `camera_ready_smoke_all_planners_smoke3_20260217_112307`
  - `total_runs=7`, `successful_runs=7`, `total_episodes=7`
- full all-planners:
  - `camera_ready_all_planners_full2_20260217_112600`
  - `total_runs=7`, `successful_runs=7`, `total_episodes=315`
  - campaign runtime: `130.03s`
  - publication bundle created

Artifact locations:

- campaign root:
  - `output/benchmarks/camera_ready/camera_ready_all_planners_snqi_multiseed_verify_20260217_123437`
- publication bundle:
  - `output/benchmarks/publication/camera_ready_all_planners_snqi_multiseed_verify_20260217_123437_publication_bundle`

## Remaining Camera-Ready Gaps

The pipeline is complete and reproducible, but final publication-grade reporting
still requires:

- release metadata finalization:
  - replace `release_tag`/DOI placeholders in campaign config before archival
