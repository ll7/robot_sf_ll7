# Issue 403: PPO expert training config for grid+SocNav observations.
# Differential drive with backwards motion enabled.
policy_id: ppo_expert_grid_socnav_403_diffdrive_reverse_no_holdout_15m
scenario_config: ../../scenarios/classic_interactions_francis2023.yaml
num_envs: auto
worker_mode: auto
seeds:
  - 123
  - 231
  - 777
  - 992
  - 1337
# 10M steps per seed (full run). Use 0.5â€“1M for smoke tests.
total_timesteps: 15000000
feature_extractor: grid_socnav
feature_extractor_kwargs:
  grid_channels: [32, 64, 64]
  grid_kernel_sizes: [5, 3, 3]
  socnav_hidden_dims: [128, 128]
  dropout_rate: 0.1
policy_net_arch: [256, 256]
env_overrides:
  observation_mode: socnav_struct
  use_occupancy_grid: true
  include_grid_in_observation: true
  robot_config:
    type: differential_drive
    max_linear_speed: 3.0
    max_angular_speed: 1.0
    allow_backwards: true
  grid_config:
    resolution: 0.2
    width: 32.0
    height: 32.0
    channels: [obstacles, pedestrians, combined]
    use_ego_frame: true
    center_on_robot: true
  peds_have_obstacle_forces: true
  sim_config:
    prf_config:
      is_active: true
    max_peds_per_group: 3
env_factory_kwargs:
  peds_have_obstacle_forces: true
convergence:
  success_rate: 0.9
  collision_rate: 0.05
  plateau_window: 2000
# Evaluation cadence is time-based (0.5M steps until 3M, then every 1M).
# The current trainer uses evaluation_episodes after training; keep these for manifests.
evaluation:
  frequency_episodes: 10
  evaluation_episodes: 10
  hold_out_scenarios: []
  step_schedule:
    - until_step: 3000000
      every_steps: 500000
    - every_steps: 1000000
tracking:
  tensorboard: true
  wandb:
    enabled: true
    project: robot_sf
    group: issue-403-grid
    job_type: expert-ppo
